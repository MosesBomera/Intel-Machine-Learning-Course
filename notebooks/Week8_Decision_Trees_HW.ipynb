{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We will be using the wine quality data set for these exercises. This data set contains various chemical properties of wine, such as acidity, sugar, pH, and alcohol. It also contains a quality metric (3-9, with highest being better) and a color (red or white). The name of the file is `Wine_Quality_Data.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Prerequisites\n",
    "\n",
    "Install pydotplus and seaborn in your own virtual environment\n",
    "\n",
    "!pip install pydotplus\n",
    "\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:20.515409Z",
     "start_time": "2017-05-09T23:59:20.508062Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "data_path = ['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Import the data and examine the features.\n",
    "* We will be using all of them to predict `color` (white or red), but the colors feature will need to be integer encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.203609Z",
     "start_time": "2017-05-09T23:59:20.517816Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_path = os.sep.join(data_path + ['Wine_Quality_Data.csv'])\n",
    "data = pd.read_csv(file_path, sep=',',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.237021Z",
     "start_time": "2017-05-09T23:59:21.205679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality color  \n",
       "0      9.4        5   red  \n",
       "1      9.8        5   red  \n",
       "2      9.8        5   red  \n",
       "3      9.8        6   red  \n",
       "4      9.4        5   red  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.252443Z",
     "start_time": "2017-05-09T23:59:21.240366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed_acidity           float64\n",
       "volatile_acidity        float64\n",
       "citric_acid             float64\n",
       "residual_sugar          float64\n",
       "chlorides               float64\n",
       "free_sulfur_dioxide     float64\n",
       "total_sulfur_dioxide    float64\n",
       "density                 float64\n",
       "pH                      float64\n",
       "sulphates               float64\n",
       "alcohol                 float64\n",
       "quality                   int64\n",
       "color                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the color feature to an integer. This is a quick way to do it using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.265375Z",
     "start_time": "2017-05-09T23:59:21.255260Z"
    }
   },
   "outputs": [],
   "source": [
    "data['color'] = data.color.replace(['white','red'],[0,1]).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  color  \n",
       "0      9.4        5      1  \n",
       "1      9.8        5      1  \n",
       "2      9.8        5      1  \n",
       "3      9.8        6      1  \n",
       "4      9.4        5      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Use `StratifiedShuffleSplit` to split data into train and test sets that are stratified by wine quality. If possible, preserve the indices of the split for question 5 below.\n",
    "* Check the percent composition of each quality level for both the train and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.274460Z",
     "start_time": "2017-05-09T23:59:21.270038Z"
    }
   },
   "outputs": [],
   "source": [
    "# All data columns except for color\n",
    "feature_cols = [x for x in data.columns if x not in 'color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.627973Z",
     "start_time": "2017-05-09T23:59:21.283564Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "strat_shuff_split = StratifiedShuffleSplit(n_splits=1, test_size=1000,random_state=45)\n",
    "\n",
    "train_idx, test_idx = next(strat_shuff_split.split(data[feature_cols],data['color']))\n",
    "\n",
    "# Create the data sets\n",
    "X_train = data.loc[train_idx, feature_cols]\n",
    "y_train = data.loc[train_idx, 'color']\n",
    "\n",
    "X_test = data.loc[test_idx, feature_cols]\n",
    "y_test = data.loc[test_idx, 'color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the percent composition of each quality level in the train and test data sets. The data set is mostly white wine, as can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.639032Z",
     "start_time": "2017-05-09T23:59:21.629538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.753866\n",
       "1    0.246134\n",
       "Name: color, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.648983Z",
     "start_time": "2017-05-09T23:59:21.641824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.754\n",
       "1    0.246\n",
       "Name: color, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.066</td>\n",
       "      <td>26.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99456</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.72</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>8.4</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.038</td>\n",
       "      <td>45.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.99178</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>8.4</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.082</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.99760</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.44</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3287</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.041</td>\n",
       "      <td>118.5</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.63</td>\n",
       "      <td>9.4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3379</th>\n",
       "      <td>8.4</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.31</td>\n",
       "      <td>5.40</td>\n",
       "      <td>0.052</td>\n",
       "      <td>47.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99530</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "1264            8.5              0.37         0.32            1.80      0.066   \n",
       "5552            8.4              0.22         0.30            1.30      0.038   \n",
       "720             8.4              0.56         0.04            2.00      0.082   \n",
       "3287            6.7              0.25         0.26            1.55      0.041   \n",
       "3379            8.4              0.17         0.31            5.40      0.052   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "1264                 26.0                  51.0  0.99456  3.38       0.72   \n",
       "5552                 45.0                 122.0  0.99178  3.13       0.54   \n",
       "720                  10.0                  22.0  0.99760  3.22       0.44   \n",
       "3287                118.5                 216.0  0.99490  3.55       0.63   \n",
       "3379                 47.0                 150.0  0.99530  3.24       0.38   \n",
       "\n",
       "      alcohol  quality  \n",
       "1264     11.8        6  \n",
       "5552     10.8        7  \n",
       "720       9.6        5  \n",
       "3287      9.4        3  \n",
       "3379      9.8        5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "* Fit a decision tree classifier with no set limits on maximum depth, features, or leaves.\n",
    "* Determine how many nodes are present and what the depth of this (very large) tree is.\n",
    "* Using this tree, measure the prediction error in the train and test data sets. What do you think is going on here based on the differences in prediction error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.711217Z",
     "start_time": "2017-05-09T23:59:21.651488Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes and the maximum actual depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.717346Z",
     "start_time": "2017-05-09T23:59:21.712743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.tree_.node_count, dt.tree_.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to return error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.730535Z",
     "start_time": "2017-05-09T23:59:21.723077Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def measure_error(y_true, y_pred, label):\n",
    "    return pd.Series({'accuracy': accuracy_score(y_true, y_pred),\n",
    "                      'precision': precision_score(y_true,y_pred),\n",
    "                      'recall': recall_score(y_true, y_pred),\n",
    "                      'f1':f1_score(y_true, y_pred)},\n",
    "                    name=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree predicts a little better on the training data than the test data, which is consistent with (mild)  overfitting. Also notice the perfect recall score for the training data. In many instances, this prediction difference is even greater than that seen here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.751859Z",
     "start_time": "2017-05-09T23:59:21.732680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.999636</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.999261</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.999261</td>\n",
       "      <td>0.951220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.999261</td>\n",
       "      <td>0.949290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.999636  0.975000\n",
       "precision  0.999261  0.947368\n",
       "recall     0.999261  0.951220\n",
       "f1         0.999261  0.949290"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The error on the training and test data sets\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "train_test_full_error = pd.concat([measure_error(y_train, y_train_pred, 'train'),\n",
    "                              measure_error(y_test, y_test_pred, 'test')],\n",
    "                              axis=1)\n",
    "\n",
    "train_test_full_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "* Using grid search with cross validation, find a decision tree that performs well on the test data set. Use a different variable name for this decision tree model than in question 3 so that both can be used in question 6.\n",
    "* Determine the number of nodes and the depth of this tree.\n",
    "* Measure the errors on the training and test sets as before and compare them to those from the tree in question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:24.274020Z",
     "start_time": "2017-05-09T23:59:21.753343Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth':range(1, dt.tree_.max_depth+1, 2),\n",
    "              'max_features': range(1, len(dt.feature_importances_)+1)}\n",
    "\n",
    "GR = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  n_jobs=-1)\n",
    "\n",
    "GR = GR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes and the maximum depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:24.280804Z",
     "start_time": "2017-05-09T23:59:24.275977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GR.best_estimator_.tree_.node_count, GR.best_estimator_.tree_.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These test errors are a little better than the previous ones. So it would seem the previous example overfit the data, but only slightly so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:24.295309Z",
     "start_time": "2017-05-09T23:59:24.282493Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_pred_gr = GR.predict(X_train)\n",
    "y_test_pred_gr = GR.predict(X_test)\n",
    "\n",
    "train_test_gr_error = pd.concat([measure_error(y_train, y_train_pred_gr, 'train'),\n",
    "                                 measure_error(y_test, y_test_pred_gr, 'test')],\n",
    "                                axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:24.303642Z",
     "start_time": "2017-05-09T23:59:24.296649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.997089</td>\n",
       "      <td>0.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.997766</td>\n",
       "      <td>0.974468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.990392</td>\n",
       "      <td>0.930894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.994065</td>\n",
       "      <td>0.952183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.997089  0.977000\n",
       "precision  0.997766  0.974468\n",
       "recall     0.990392  0.930894\n",
       "f1         0.994065  0.952183"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_gr_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "* Re-split the data into `X` and `y` parts, this time with `residual_sugar` being the predicted (`y`) data. *Note:* if the indices were preserved from the `StratifiedShuffleSplit` output in question 2, they can be used again to split the data.\n",
    "* Using grid search with cross validation, find a decision tree **regression** model that performs well on the test data set.\n",
    "* Measure the errors on the training and test sets using mean squared error.\n",
    "* Make a plot of actual *vs* predicted residual sugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:24.317443Z",
     "start_time": "2017-05-09T23:59:24.305043Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_cols = [x for x in data.columns if x != 'residual_sugar']\n",
    "\n",
    "X_train = data.loc[train_idx, feature_cols]\n",
    "y_train = data.loc[train_idx, 'residual_sugar']\n",
    "\n",
    "X_test = data.loc[test_idx, feature_cols]\n",
    "y_test = data.loc[test_idx, 'residual_sugar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:28.931614Z",
     "start_time": "2017-05-09T23:59:24.318919Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dr = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "\n",
    "param_grid = {'max_depth': range(1, dr.tree_.max_depth+1,2),\n",
    "              'max_features': range(1, len(dr.feature_importances_)+1)}\n",
    "\n",
    "GR_sugar = GridSearchCV(DecisionTreeRegressor(random_state=45), \n",
    "                  param_grid=param_grid,\n",
    "                  scoring='neg_mean_squared_error',\n",
    "                  n_jobs=-1)\n",
    "GR_sugar = GR_sugar.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes and the maximum depth of the tree. This tree has lots of nodes, which is not so surprising given the continuous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:28.941182Z",
     "start_time": "2017-05-09T23:59:28.933876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7659, 25)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GR_sugar.best_estimator_.tree_.node_count, GR_sugar.best_estimator_.tree_.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error on train and test data sets. Since this is continuous, we will use mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:28.962134Z",
     "start_time": "2017-05-09T23:59:28.943461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>2.997738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train      test\n",
       "mse  0.000156  2.997738"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_train_sugar_pred = GR_sugar.predict(X_train)\n",
    "y_test_sugar_pred = GR_sugar.predict(X_test)\n",
    "\n",
    "train_test_gr_sugar_error = pd.Series({'train': mean_squared_error(y_train,y_train_sugar_pred),\n",
    "                                       'test': mean_squared_error(y_test, y_test_sugar_pred)},\n",
    "                                      name='mse').to_frame().T\n",
    "train_test_gr_sugar_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot of actual vs predicted residual sugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:29.172915Z",
     "start_time": "2017-05-09T23:59:28.964448Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "sns.set_palette('dark')\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:29.415847Z",
     "start_time": "2017-05-09T23:59:29.174948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = plt.axes()\n",
    "\n",
    "ph_test_predict = pd.DataFrame({'test':y_test.values,\n",
    "                                'predict': y_test_sugar_pred}).set_index('test').sort_index()\n",
    "\n",
    "ph_test_predict.plot(marker='o', ls='', ax=ax)\n",
    "ax.set(xlabel='Test', ylabel='Predict', xlim=(0,35), ylim=(0,35));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 *(Optional)*\n",
    "\n",
    "This question is optional as it requires an additional command line program (GraphViz) and Python library (PyDotPlus). GraphViz can be installed with a package manager on Linux and Mac. For PyDotPlus, either `pip` or `conda` (`conda install -c conda-forge pydotplus`) can be used to install the library.\n",
    "\n",
    "Once these programs are installed:\n",
    "\n",
    "* Create a visualization of the decision tree from question 3, where wine color was predicted and the number of features and/or splits are not limited.\n",
    "* Create a visualization of the decision tree from question 4, where wine color was predicted but a grid search was used to find the optimal depth and number of features.\n",
    "\n",
    "The decision tree from question 5 will likely have too many nodes to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:29.435753Z",
     "start_time": "2017-05-09T23:59:29.417461Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Display' from 'IPython.display' (C:\\Users\\Bomera Moses\\Anaconda3\\lib\\site-packages\\IPython\\display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3df183839ee3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Display' from 'IPython.display' (C:\\Users\\Bomera Moses\\Anaconda3\\lib\\site-packages\\IPython\\display.py)"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "from IPython.display import Image, Display\n",
    "\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree from question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:31.771292Z",
     "start_time": "2017-05-09T23:59:29.437977Z"
    }
   },
   "outputs": [],
   "source": [
    "if pydotplus_installed:\n",
    "    \n",
    "    # Create an output destination for the file\n",
    "    dot_data = StringIO()\n",
    "\n",
    "    export_graphviz(dt, out_file=dot_data, filled=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    print(graph)\n",
    "    # View the tree image\n",
    "    filename = 'wine_tree.png'\n",
    "    graph.write_png(filename)\n",
    "    img = Image(filename=filename)\n",
    "    display(img)\n",
    "    \n",
    "else:\n",
    "    print('This cell not executed because PyDotPlus could not be loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree fit with cross validation from question 4. This tree is much shallower than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:34.027107Z",
     "start_time": "2017-05-09T23:59:31.773741Z"
    }
   },
   "outputs": [],
   "source": [
    "if pydotplus_installed:\n",
    "    \n",
    "    # Create an output destination for the file\n",
    "    dot_data = StringIO()\n",
    "\n",
    "    export_graphviz(GR.best_estimator_, out_file=dot_data, filled=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "    # View the tree image\n",
    "    filename = 'wine_tree_prune.png'\n",
    "    graph.write_png(filename)\n",
    "    img = Image(filename=filename) \n",
    "    display(img)\n",
    "    \n",
    "else:\n",
    "    print('This cell not executed because PyDotPlus could not be loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 7\n",
    "* Import the iris data and examine the features.\n",
    "* We will be using all of them to predict species, but the species feature will need to be integer encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    float64\n",
       "sepal_width     float64\n",
       "petal_length    float64\n",
       "petal_width     float64\n",
       "species          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.sep.join(data_path+['Iris_Data.csv'])\n",
    "data = pd.read_csv(file_path, sep=',', header=0)\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-setosa        50\n",
       "Iris-virginica     50\n",
       "Iris-versicolor    50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.species.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the species feature to an integer. This is a quick way to do it using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.265375Z",
     "start_time": "2017-05-09T23:59:21.255260Z"
    }
   },
   "outputs": [],
   "source": [
    "data['species'] = data.species.replace(['Iris-virginica','Iris-setosa','Iris-versicolor'],[0,1,2]).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "98            5.1          2.5           3.0          1.1        2\n",
       "111           6.4          2.7           5.3          1.9        0\n",
       "84            5.4          3.0           4.5          1.5        2\n",
       "2             4.7          3.2           1.3          0.2        1\n",
       "30            4.8          3.1           1.6          0.2        1\n",
       "89            5.5          2.5           4.0          1.3        2\n",
       "15            5.7          4.4           1.5          0.4        1\n",
       "78            6.0          2.9           4.5          1.5        2\n",
       "95            5.7          3.0           4.2          1.2        2\n",
       "129           7.2          3.0           5.8          1.6        0\n",
       "51            6.4          3.2           4.5          1.5        2\n",
       "26            5.0          3.4           1.6          0.4        1\n",
       "100           6.3          3.3           6.0          2.5        0\n",
       "76            6.8          2.8           4.8          1.4        2\n",
       "7             5.0          3.4           1.5          0.2        1\n",
       "73            6.1          2.8           4.7          1.2        2\n",
       "31            5.4          3.4           1.5          0.4        1\n",
       "105           7.6          3.0           6.6          2.1        0\n",
       "5             5.4          3.9           1.7          0.4        1\n",
       "12            4.8          3.0           1.4          0.1        1\n",
       "75            6.6          3.0           4.4          1.4        2\n",
       "16            5.4          3.9           1.3          0.4        1\n",
       "54            6.5          2.8           4.6          1.5        2\n",
       "86            6.7          3.1           4.7          1.5        2\n",
       "64            5.6          2.9           3.6          1.3        2\n",
       "113           5.7          2.5           5.0          2.0        0\n",
       "145           6.7          3.0           5.2          2.3        0\n",
       "44            5.1          3.8           1.9          0.4        1\n",
       "142           5.8          2.7           5.1          1.9        0\n",
       "147           6.5          3.0           5.2          2.0        0\n",
       "..            ...          ...           ...          ...      ...\n",
       "72            6.3          2.5           4.9          1.5        2\n",
       "92            5.8          2.6           4.0          1.2        2\n",
       "137           6.4          3.1           5.5          1.8        0\n",
       "120           6.9          3.2           5.7          2.3        0\n",
       "47            4.6          3.2           1.4          0.2        1\n",
       "114           5.8          2.8           5.1          2.4        0\n",
       "0             5.1          3.5           1.4          0.2        1\n",
       "80            5.5          2.4           3.8          1.1        2\n",
       "65            6.7          3.1           4.4          1.4        2\n",
       "83            6.0          2.7           5.1          1.6        2\n",
       "126           6.2          2.8           4.8          1.8        0\n",
       "104           6.5          3.0           5.8          2.2        0\n",
       "77            6.7          3.0           5.0          1.7        2\n",
       "59            5.2          2.7           3.9          1.4        2\n",
       "52            6.9          3.1           4.9          1.5        2\n",
       "36            5.5          3.5           1.3          0.2        1\n",
       "132           6.4          2.8           5.6          2.2        0\n",
       "69            5.6          2.5           3.9          1.1        2\n",
       "119           6.0          2.2           5.0          1.5        0\n",
       "122           7.7          2.8           6.7          2.0        0\n",
       "85            6.0          3.4           4.5          1.6        2\n",
       "71            6.1          2.8           4.0          1.3        2\n",
       "109           7.2          3.6           6.1          2.5        0\n",
       "61            5.9          3.0           4.2          1.5        2\n",
       "25            5.0          3.0           1.6          0.2        1\n",
       "37            4.9          3.1           1.5          0.1        1\n",
       "39            5.1          3.4           1.5          0.2        1\n",
       "101           5.8          2.7           5.1          1.9        0\n",
       "140           6.7          3.1           5.6          2.4        0\n",
       "3             4.6          3.1           1.5          0.2        1\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "* Use `StratifiedShuffleSplit` to split data into train and test sets that are stratified by species. If possible, preserve the indices of the split for question 11 below.\n",
    "* Check the percent composition of each species level for both the train and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.274460Z",
     "start_time": "2017-05-09T23:59:21.270038Z"
    }
   },
   "outputs": [],
   "source": [
    "# All data columns except for species\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "feature_cols = [x for x in data.columns if x != 'species']\n",
    "\n",
    "strat_shuff_split = StratifiedShuffleSplit(n_splits=1,test_size=0.3, random_state=45)\n",
    "train_idx, test_idx = next(strat_shuff_split.split(data[feature_cols],data['species']))\n",
    "\n",
    "X_train = data.loc[train_idx, feature_cols]\n",
    "y_train = data.loc[train_idx, 'species']\n",
    "\n",
    "X_test = data.loc[test_idx, feature_cols ]\n",
    "y_test = data.loc[test_idx, 'species']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.627973Z",
     "start_time": "2017-05-09T23:59:21.283564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 4), (45,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the percent composition of each species in the train and test iris_data sets. The iris_data set is equally distributed, as can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.639032Z",
     "start_time": "2017-05-09T23:59:21.629538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.333333\n",
       "1    0.333333\n",
       "0    0.333333\n",
       "Name: species, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.648983Z",
     "start_time": "2017-05-09T23:59:21.641824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.333333\n",
       "1    0.333333\n",
       "0    0.333333\n",
       "Name: species, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "* Fit a decision tree classifier with no set limits on maximum depth, features, or leaves.\n",
    "* Determine how many nodes are present and what the depth of this (very large) tree is.\n",
    "* Using this tree, measure the prediction error in the train and test iris_data sets. What do you think is going on here based on the differences in prediction error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.711217Z",
     "start_time": "2017-05-09T23:59:21.651488Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DTC = DecisionTreeClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes and the maximum actual depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.717346Z",
     "start_time": "2017-05-09T23:59:21.712743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTC.tree_.node_count, DTC.tree_.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to return error metrics.\n",
    "#### HINT: This is not a binary classification problem, IRIS data set has 3 classes in target column. Check on score functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.730535Z",
     "start_time": "2017-05-09T23:59:21.723077Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def measure_error(y_true, y_pred, label):\n",
    "    return pd.Series({'accuracy':accuracy_score(y_true, y_pred),\n",
    "                      'precision':precision_score(y_true, y_pred, average='macro'),\n",
    "                      'recall':recall_score(y_true, y_pred, average='macro'),\n",
    "                      'f1_score':f1_score(y_true, y_pred, average='macro')}, name=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree predicts a little better on the training iris_data than the test iris_data, which is consistent with (mild)  overfitting. Also notice the perfect recall score for the training iris_data. In many instances, this prediction difference is even greater than that seen here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:21.751859Z",
     "start_time": "2017-05-09T23:59:21.732680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train      test\n",
       "accuracy     1.0  0.955556\n",
       "precision    1.0  0.960784\n",
       "recall       1.0  0.955556\n",
       "f1_score     1.0  0.955357"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = DTC.predict(X_train)\n",
    "y_test_pred = DTC.predict(X_test)\n",
    "\n",
    "error_metrics = pd.concat([measure_error(y_train, y_train_pred, 'train'),\n",
    "                          measure_error(y_test, y_test_pred, 'test')], axis=1)\n",
    "error_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "147           6.5          3.0           5.2          2.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[feature_cols].iloc[147:148,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = DTC.predict(data[feature_cols].iloc[29:30,])\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Question 10\n",
    "\n",
    "* Using grid search with cross validation, find a decision tree that performs well on the test iris_data set. Use a different variable name for this decision tree model than in question 9 so that both can be used in question 12.\n",
    "* Determine the number of nodes and the depth of this tree.\n",
    "* Measure the errors on the training and test sets as before and compare them to those from the tree in question 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:24.274020Z",
     "start_time": "2017-05-09T23:59:21.753343Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bomera Moses\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Bomera Moses\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': range(1, DTC.tree_.max_depth+1,2),\n",
    "              'max_features': range(1,len(DTC.feature_importances_)+1)}\n",
    "\n",
    "GR = GridSearchCV(DecisionTreeClassifier(random_state=45),\n",
    "                 param_grid=param_grid,\n",
    "                 scoring='accuracy',\n",
    "                 n_jobs=-1)\n",
    "\n",
    "GR = GR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes and the maximum depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:24.280804Z",
     "start_time": "2017-05-09T23:59:24.275977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GR.best_estimator_.tree_.node_count, GR.best_estimator_.tree_.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These test errors are a little better than the previous ones. So it would seem the previous example overfit the iris_data, but only slightly so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:24.295309Z",
     "start_time": "2017-05-09T23:59:24.282493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.990474</td>\n",
       "      <td>0.955357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.990476  0.955556\n",
       "precision  0.990741  0.960784\n",
       "recall     0.990476  0.955556\n",
       "f1_score   0.990474  0.955357"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_gr_pred = GR.predict(X_train)\n",
    "y_test_gr_pred = GR.predict(X_test)\n",
    "\n",
    "error_metrics = pd.concat([measure_error(y_train, y_train_gr_pred, 'train'),\n",
    "                           measure_error(y_test, y_test_gr_pred, 'test')], axis=1)\n",
    "\n",
    "error_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 11\n",
    "\n",
    "* Re-split the iris_data into `X` and `y` parts, this time with `species` being the predicted (`y`) iris_data. *Note:* if the indices were preserved from the `StratifiedShuffleSplit` output in question 8, they can be used again to split the iris_data.\n",
    "* Using grid search with cross validation, find a decision tree **regression** model that performs well on the test iris_data set.\n",
    "* Measure the errors on the training and test sets using mean squared error.\n",
    "* Make a plot of actual *vs* predicted species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:24.317443Z",
     "start_time": "2017-05-09T23:59:24.305043Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes and the maximum depth of the tree. This tree has lots of nodes, which is not so surprising given the continuous iris_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:28.941182Z",
     "start_time": "2017-05-09T23:59:28.933876Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error on train and test iris_data sets. Since this is continuous, we will use mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:28.962134Z",
     "start_time": "2017-05-09T23:59:28.943461Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot of actual vs predicted species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:29.415847Z",
     "start_time": "2017-05-09T23:59:29.174948Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12 *(Optional)*\n",
    "\n",
    "This question is optional as it requires an additional command line program (GraphViz) and Python library (PyDotPlus). GraphViz can be installed with a package manager on Linux and Mac. For PyDotPlus, either `pip` or `conda` (`conda install -c conda-forge pydotplus`) can be used to install the library.\n",
    "\n",
    "Once these programs are installed:\n",
    "\n",
    "* Create a visualization of the decision tree from question 9, where wine species was predicted and the number of features and/or splits are not limited.\n",
    "* Create a visualization of the decision tree from question 10, where wine species was predicted but a grid search was used to find the optimal depth and number of features.\n",
    "\n",
    "The decision tree from question 11 will likely have too many nodes to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:29.435753Z",
     "start_time": "2017-05-09T23:59:29.417461Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree from question 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:31.771292Z",
     "start_time": "2017-05-09T23:59:29.437977Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree fit with cross validation from question 10. This tree is much shallower than the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-09T23:59:34.027107Z",
     "start_time": "2017-05-09T23:59:31.773741Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
